# 3-Node Local Simulation Configuration
# Simulates heterogeneous nodes with different VRAM capacities

model:
  name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  dtype: "float16"

coordinator:
  host: "localhost"
  port: 50050
  heartbeat_interval_sec: 3.0
  heartbeat_timeout_sec: 10.0
  failure_threshold: 3

# Individual nodes are configured via CLI flags:
#   Node 1: --port 50051 --max-vram-mb 512   (small node)
#   Node 2: --port 50052 --max-vram-mb 1024  (medium node)
#   Node 3: --port 50053 --max-vram-mb 1536  (large node)

inference:
  max_tokens: 30
  temperature: 0.7
  top_p: 0.9
  enable_kv_cache: true

communication:
  compress_tensors: false
  max_message_size_mb: 256
